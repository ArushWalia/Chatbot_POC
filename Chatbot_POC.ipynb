{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c623f73",
   "metadata": {},
   "source": [
    "# BERT Chatbot POC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df33672",
   "metadata": {},
   "source": [
    "To build a chatbot, i will devide the process in 4 diffrent step \n",
    "- Importing and reading the PDF files \n",
    "- Importing COQA data set \n",
    "- Building the chatbot using BERT \n",
    "- Merging the model and the PDF retrived data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "688d1c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required liberaries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import glob\n",
    "#import nltk \n",
    "import re\n",
    "import random \n",
    "import string \n",
    "#import os\n",
    "import torch\n",
    "from transformers import BertTokenizerFast,BertForQuestionAnswering\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2301a6",
   "metadata": {},
   "source": [
    "# Importing and reading PDF files \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c63e6c",
   "metadata": {},
   "source": [
    "To import and read PDF files PyPDF2 liberary is used to read the PDF pages and extract text from them. \n",
    "To retrive the PDF files stored in a folder Glob is used to return all file paths to match a specific pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79d8c5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "pdf_dir =\"C:/Users/Arush/OneDrive/Desktop/sample\"\n",
    "pdf_files = glob.glob(\"%s/*.pdf\" % pdf_dir , recursive = True)\n",
    "\n",
    "text = \" \"\n",
    "# creating a pdf file object \n",
    "for pdf_file in pdf_files:\n",
    "    pdfFileObj = open(pdf_file, 'rb') \n",
    "    # creating a pdf reader object \n",
    " \n",
    "    pdfReader = PyPDF2.PdfFileReader(pdfFileObj, strict= False) \n",
    "    # printing number of pages in pdf file \n",
    "    print(pdfReader.numPages) \n",
    "    Page = pdfReader.getNumPages()\n",
    "    \n",
    "   \n",
    "    for i in range(0,Page):\n",
    "        # creating a page object \n",
    "        pageObj = pdfReader.getPage(i) \n",
    "        # extracting text from page \n",
    "        text += pageObj.extractText()\n",
    "    pdfFileObj.close()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dd31b4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I would like to get your all thoughts on the bond yield increase this week. I am not worried about the market downturn but the sudden increase in yields. On 2/16 the 10 year bonds yields increased by almost 9 percent and on 2/19 the yield increased by almost 5 percent. Key Points from the CNBC Article: to market panic after the Federal Reserve announced that it would begin tapering its quantitative easing program.** * **Major central banks around the world have cut interest rates to historic lows and launched unprecedented quantities of asset purchases in a bid to shore up the economy throughout the pandemic.** * **However, the recent r ise in yields suggests that some investors are starting to anticipate a tightening of policy sooner than anticipated to accommodate a potential rise in inflation.** The recent rise in bond yields and U.S. inflation expectations has some investors wary tha horizon. The benchmark U.S. 10 - year Treasury note climbed above 1.3% for the first time since February 2020 earlier this week, while the 30 - year bond also hit its highest level for a year. Yields move inversely to bond prices. Yields tend to rise in lockstep with inflation expectations, which have reached their highest levels in a decade in the U.S., powered by increased prospects of a large fiscal stimulus package, progress on vaccine rollouts and pe nt - up consumer demand. market panic after the Federal Reserve announced that it would begin tapering its quantitative easing program. Major central banks around the world have cut i nterest rates to historic lows and launched unprecedented quantities of asset purchases in a bid to shore up the economy throughout the pandemic. The Fed and others have maintained supportive tones in recent policy meetings, vowing to keep financial condit ions loose as the global economy looks to emerge from the Covid - 19 pandemic. However, the recent rise in yields suggests that some investors are starting to anticipate a tightening of policy sooner than anticipated to accommodate a potential rise in infla tion. With central bank support removed, bonds usually fall in price which sends yields higher. This can also spill over into stock markets as higher interest rates means more debt servicing for firms, causing traders to reassess the investing environment . Balkham, chief investment officer at Beaufort Investment, in a research note this week. '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using Regular Expression for cleaning the text \n",
    "\n",
    "PDF_text = re.sub(r'\\[[0-9]*\\]',' ', text)\n",
    "PDF_text = re.sub(r'\\s+',' ', text)\n",
    "\n",
    "PDF_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12bbacf",
   "metadata": {},
   "source": [
    "# Importing COQA data set "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c3c9a0",
   "metadata": {},
   "source": [
    "CoQA (conversational question answering dataset) is large scaled data used for building conversational question answering system. It contains 127,000+ questions with answers collected from 8000+ conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "103aa81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Data \n",
    "coqa = pd.read_json('http://downloads.cs.stanford.edu/nlp/data/coqa/coqa-train-v1.0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "595eb838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'wikipedia', 'id': '3zotghdk5ibi9cex97fepx7jetpso7', 'filename': 'Vatican_Library.txt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'cnn', 'id': '3wj1oxy92agboo5nlq4r7bndc3t8a8', 'filename': 'cnn_fe05c61a7e48461f7883c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'gutenberg', 'id': '3bdcf01ogxu7zdn9vlrbf2rqzwplyf', 'filename': 'data/gutenberg/txt/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'cnn', 'id': '3ewijtffvo7wwchw6rtyaf7mfwte0p', 'filename': 'cnn_0c518067e0df811501e46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'gutenberg', 'id': '3urfvvm165iantk80llvkwwbjs7uzh', 'filename': 'data/gutenberg/txt/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7194</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'gutenberg', 'id': '34j10vatjfyw0aohj8d4a0wwku3qif', 'filename': 'data/gutenberg/txt/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7195</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'cnn', 'id': '3vj40nv2qinjocrcy7k4z235g6aotn', 'filename': 'cnn_ef5596ece4a9de118290e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7196</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'race', 'id': '3rjsc4xj10uw0to3vq0v6l191rz05q', 'filename': 'middle8160.txt', 'story'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7197</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'wikipedia', 'id': '3gs6s824sqxty8vusxp27xazutmnw2', 'filename': 'Frankfurt.txt', 'st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7198</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'cnn', 'id': '31qnsg6a5rtt5m7pens7xklnbwf87b', 'filename': 'cnn_512d145c235e998513628...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7199 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      version  \\\n",
       "0           1   \n",
       "1           1   \n",
       "2           1   \n",
       "3           1   \n",
       "4           1   \n",
       "...       ...   \n",
       "7194        1   \n",
       "7195        1   \n",
       "7196        1   \n",
       "7197        1   \n",
       "7198        1   \n",
       "\n",
       "                                                                                                     data  \n",
       "0     {'source': 'wikipedia', 'id': '3zotghdk5ibi9cex97fepx7jetpso7', 'filename': 'Vatican_Library.txt...  \n",
       "1     {'source': 'cnn', 'id': '3wj1oxy92agboo5nlq4r7bndc3t8a8', 'filename': 'cnn_fe05c61a7e48461f7883c...  \n",
       "2     {'source': 'gutenberg', 'id': '3bdcf01ogxu7zdn9vlrbf2rqzwplyf', 'filename': 'data/gutenberg/txt/...  \n",
       "3     {'source': 'cnn', 'id': '3ewijtffvo7wwchw6rtyaf7mfwte0p', 'filename': 'cnn_0c518067e0df811501e46...  \n",
       "4     {'source': 'gutenberg', 'id': '3urfvvm165iantk80llvkwwbjs7uzh', 'filename': 'data/gutenberg/txt/...  \n",
       "...                                                                                                   ...  \n",
       "7194  {'source': 'gutenberg', 'id': '34j10vatjfyw0aohj8d4a0wwku3qif', 'filename': 'data/gutenberg/txt/...  \n",
       "7195  {'source': 'cnn', 'id': '3vj40nv2qinjocrcy7k4z235g6aotn', 'filename': 'cnn_ef5596ece4a9de118290e...  \n",
       "7196  {'source': 'race', 'id': '3rjsc4xj10uw0to3vq0v6l191rz05q', 'filename': 'middle8160.txt', 'story'...  \n",
       "7197  {'source': 'wikipedia', 'id': '3gs6s824sqxty8vusxp27xazutmnw2', 'filename': 'Frankfurt.txt', 'st...  \n",
       "7198  {'source': 'cnn', 'id': '31qnsg6a5rtt5m7pens7xklnbwf87b', 'filename': 'cnn_512d145c235e998513628...  \n",
       "\n",
       "[7199 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coqa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746544f9",
   "metadata": {},
   "source": [
    "## Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54824232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting version column \n",
    "del coqa[\"version\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9eb4b2",
   "metadata": {},
   "source": [
    "The Bert model for Question answering trains the model with the data in the form of question context pair. So changing the data in the required format and linking the question and answer to the linked story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f968b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#required columns in a dataframe \n",
    "cols = ['text','question','answer']\n",
    "\n",
    "comp_list =[]\n",
    "for index, row in coqa.iterrows():\n",
    "    for i in range(len(row['data']['questions'])):\n",
    "        temp_list = []\n",
    "        temp_list.append(row['data']['story'])\n",
    "        temp_list.append(row['data']['questions'][i]['input_text'])\n",
    "        temp_list.append(row['data']['answers'][i]['input_text'])\n",
    "        comp_list.append(temp_list)\n",
    "        \n",
    "new_df = pd.DataFrame(comp_list,columns = cols)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ad19dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the dataframe in to csv \n",
    "\n",
    "new_df.to_csv('coqa_data.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfea9e43",
   "metadata": {},
   "source": [
    "## Loading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ca9f021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonly called the Vatican Library or simply the Vat, is...</td>\n",
       "      <td>When was the Vat formally opened?</td>\n",
       "      <td>It was formally established in 1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonly called the Vatican Library or simply the Vat, is...</td>\n",
       "      <td>what is the library for?</td>\n",
       "      <td>research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonly called the Vatican Library or simply the Vat, is...</td>\n",
       "      <td>for what subjects?</td>\n",
       "      <td>history, and law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonly called the Vatican Library or simply the Vat, is...</td>\n",
       "      <td>and?</td>\n",
       "      <td>philosophy, science and theology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonly called the Vatican Library or simply the Vat, is...</td>\n",
       "      <td>what was started in 2014?</td>\n",
       "      <td>a  project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108642</th>\n",
       "      <td>(CNN) -- Cristiano Ronaldo provided the perfect riposte to FIFA president Sepp Blatter after sco...</td>\n",
       "      <td>Who was a sub?</td>\n",
       "      <td>Xabi Alonso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108643</th>\n",
       "      <td>(CNN) -- Cristiano Ronaldo provided the perfect riposte to FIFA president Sepp Blatter after sco...</td>\n",
       "      <td>Was it his first game this year?</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108644</th>\n",
       "      <td>(CNN) -- Cristiano Ronaldo provided the perfect riposte to FIFA president Sepp Blatter after sco...</td>\n",
       "      <td>What position did the team reach?</td>\n",
       "      <td>third</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108645</th>\n",
       "      <td>(CNN) -- Cristiano Ronaldo provided the perfect riposte to FIFA president Sepp Blatter after sco...</td>\n",
       "      <td>Who was ahead of them?</td>\n",
       "      <td>Barca.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108646</th>\n",
       "      <td>(CNN) -- Cristiano Ronaldo provided the perfect riposte to FIFA president Sepp Blatter after sco...</td>\n",
       "      <td>By how much?</td>\n",
       "      <td>six points</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108647 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                       text  \\\n",
       "0       The Vatican Apostolic Library (), more commonly called the Vatican Library or simply the Vat, is...   \n",
       "1       The Vatican Apostolic Library (), more commonly called the Vatican Library or simply the Vat, is...   \n",
       "2       The Vatican Apostolic Library (), more commonly called the Vatican Library or simply the Vat, is...   \n",
       "3       The Vatican Apostolic Library (), more commonly called the Vatican Library or simply the Vat, is...   \n",
       "4       The Vatican Apostolic Library (), more commonly called the Vatican Library or simply the Vat, is...   \n",
       "...                                                                                                     ...   \n",
       "108642  (CNN) -- Cristiano Ronaldo provided the perfect riposte to FIFA president Sepp Blatter after sco...   \n",
       "108643  (CNN) -- Cristiano Ronaldo provided the perfect riposte to FIFA president Sepp Blatter after sco...   \n",
       "108644  (CNN) -- Cristiano Ronaldo provided the perfect riposte to FIFA president Sepp Blatter after sco...   \n",
       "108645  (CNN) -- Cristiano Ronaldo provided the perfect riposte to FIFA president Sepp Blatter after sco...   \n",
       "108646  (CNN) -- Cristiano Ronaldo provided the perfect riposte to FIFA president Sepp Blatter after sco...   \n",
       "\n",
       "                                 question                               answer  \n",
       "0       When was the Vat formally opened?  It was formally established in 1475  \n",
       "1                what is the library for?                             research  \n",
       "2                      for what subjects?                     history, and law  \n",
       "3                                    and?     philosophy, science and theology  \n",
       "4               what was started in 2014?                           a  project  \n",
       "...                                   ...                                  ...  \n",
       "108642                     Who was a sub?                          Xabi Alonso  \n",
       "108643   Was it his first game this year?                                  Yes  \n",
       "108644  What position did the team reach?                                third  \n",
       "108645             Who was ahead of them?                               Barca.  \n",
       "108646                       By how much?                           six points  \n",
       "\n",
       "[108647 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('coqa_data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ee9ecf",
   "metadata": {},
   "source": [
    "# Building the Chatbot "
   ]
  },
  {
   "cell_type": "raw",
   "id": "20a9a6bf",
   "metadata": {},
   "source": [
    "using BERT model which is already pre-trained on SQUAD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5147570",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "060329fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly selecting a question number from COQA dataset to train the model\n",
    "\n",
    "random_num = np.random.randint(8,len(data))\n",
    "\n",
    "question = data['question'][random_num]\n",
    "text = data['text'][random_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ec12471",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What did Betty do as John told her about it? \n",
      " CHAPTER XXIX \n",
      "\n",
      "A REPRESENTATIVE GATHERING \n",
      "\n",
      "When John returned to the office, he found that his absence had been causing Betty an anxious hour's waiting. She had been informed by Pugsy that he had gone out in the company of Mr. Parker, and she felt uneasy. She turned white at his story of the ride, but he minimized the dangers. \n",
      "\n",
      "\"I don't think he ever meant to shoot. I think he was going to shut me up somewhere out there, and keep me till I promised to be good.\" \n",
      "\n",
      "\"Do you think my stepfather told him to do it?\" \n",
      "\n",
      "\"I doubt it. I fancy Parker is a man who acts a good deal on his own inspirations. But we'll ask him, when he calls to-day.\" \n",
      "\n",
      "\"Is he going to call?\" \n",
      "\n",
      "\"I have an idea he will,\" said John. \"I sent him a note just now, asking if he could manage a visit.\" \n",
      "\n",
      "It was unfortunate, in the light of subsequent events, that Mr. Jarvis should have seen fit to bring with him to the office that afternoon two of his collection of cats, and that Long Otto, who, as before, accompanied him, should have been fired by his example to the extent of introducing a large yellow dog For before the afternoon was ended, space in the office was destined to be at premium. \n",
      "\n",
      "Mr. Jarvis, when he had recovered from the surprise of seeing Betty and learning that she had returned to her old situation, explained: \n",
      "\n",
      "\"T'ought I'd bring de kits along,\" he said. \"Dey starts fuss'n' wit' each odder yesterday, so I brings dem along.\" \n"
     ]
    }
   ],
   "source": [
    "print(question, '\\n' ,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "635a8185",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "The input has a total of 357 tokens.\n"
     ]
    }
   ],
   "source": [
    "#tokenzinging text and question as a pair for the model to read in the format of [cls]question[sep]context[sep]\n",
    "input_ids = tokenizer.encode_plus(question,text)\n",
    "print(input_ids.keys())\n",
    "print(\"The input has a total of {} tokens.\".format(len(input_ids['input_ids'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c045d70",
   "metadata": {},
   "source": [
    "In the output above tokenization created 3 tensors ['input_ids', 'token_type_ids', 'attention_mask']. we only need input_ids and token_type_ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f25b9bd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           101\n",
      "what          2,054\n",
      "did           2,106\n",
      "betty         9,306\n",
      "do            2,079\n",
      "as            2,004\n",
      "john          2,198\n",
      "told          2,409\n",
      "her           2,014\n",
      "about         2,055\n",
      "it            2,009\n",
      "?             1,029\n",
      "\n",
      "[SEP]           102\n",
      "\n",
      "chapter       3,127\n",
      "xx           22,038\n",
      "##ix          7,646\n",
      "a             1,037\n",
      "representative  4,387\n",
      "gathering     7,215\n",
      "when          2,043\n",
      "john          2,198\n",
      "returned      2,513\n",
      "to            2,000\n",
      "the           1,996\n",
      "office        2,436\n",
      ",             1,010\n",
      "he            2,002\n",
      "found         2,179\n",
      "that          2,008\n",
      "his           2,010\n",
      "absence       6,438\n",
      "had           2,018\n",
      "been          2,042\n",
      "causing       4,786\n",
      "betty         9,306\n",
      "an            2,019\n",
      "anxious      11,480\n",
      "hour          3,178\n",
      "'             1,005\n",
      "s             1,055\n",
      "waiting       3,403\n",
      ".             1,012\n",
      "she           2,016\n",
      "had           2,018\n",
      "been          2,042\n",
      "informed      6,727\n",
      "by            2,011\n",
      "pu           16,405\n",
      "##gs          5,620\n",
      "##y           2,100\n",
      "that          2,008\n",
      "he            2,002\n",
      "had           2,018\n",
      "gone          2,908\n",
      "out           2,041\n",
      "in            1,999\n",
      "the           1,996\n",
      "company       2,194\n",
      "of            1,997\n",
      "mr            2,720\n",
      ".             1,012\n",
      "parker        6,262\n",
      ",             1,010\n",
      "and           1,998\n",
      "she           2,016\n",
      "felt          2,371\n",
      "uneasy       15,491\n",
      ".             1,012\n",
      "she           2,016\n",
      "turned        2,357\n",
      "white         2,317\n",
      "at            2,012\n",
      "his           2,010\n",
      "story         2,466\n",
      "of            1,997\n",
      "the           1,996\n",
      "ride          4,536\n",
      ",             1,010\n",
      "but           2,021\n",
      "he            2,002\n",
      "minimize     18,478\n",
      "##d           2,094\n",
      "the           1,996\n",
      "dangers      16,796\n",
      ".             1,012\n",
      "\"             1,000\n",
      "i             1,045\n",
      "don           2,123\n",
      "'             1,005\n",
      "t             1,056\n",
      "think         2,228\n",
      "he            2,002\n",
      "ever          2,412\n",
      "meant         3,214\n",
      "to            2,000\n",
      "shoot         5,607\n",
      ".             1,012\n",
      "i             1,045\n",
      "think         2,228\n",
      "he            2,002\n",
      "was           2,001\n",
      "going         2,183\n",
      "to            2,000\n",
      "shut          3,844\n",
      "me            2,033\n",
      "up            2,039\n",
      "somewhere     4,873\n",
      "out           2,041\n",
      "there         2,045\n",
      ",             1,010\n",
      "and           1,998\n",
      "keep          2,562\n",
      "me            2,033\n",
      "till          6,229\n",
      "i             1,045\n",
      "promised      5,763\n",
      "to            2,000\n",
      "be            2,022\n",
      "good          2,204\n",
      ".             1,012\n",
      "\"             1,000\n",
      "\"             1,000\n",
      "do            2,079\n",
      "you           2,017\n",
      "think         2,228\n",
      "my            2,026\n",
      "stepfather   21,481\n",
      "told          2,409\n",
      "him           2,032\n",
      "to            2,000\n",
      "do            2,079\n",
      "it            2,009\n",
      "?             1,029\n",
      "\"             1,000\n",
      "\"             1,000\n",
      "i             1,045\n",
      "doubt         4,797\n",
      "it            2,009\n",
      ".             1,012\n",
      "i             1,045\n",
      "fancy        11,281\n",
      "parker        6,262\n",
      "is            2,003\n",
      "a             1,037\n",
      "man           2,158\n",
      "who           2,040\n",
      "acts          4,490\n",
      "a             1,037\n",
      "good          2,204\n",
      "deal          3,066\n",
      "on            2,006\n",
      "his           2,010\n",
      "own           2,219\n",
      "inspiration   7,780\n",
      "##s           2,015\n",
      ".             1,012\n",
      "but           2,021\n",
      "we            2,057\n",
      "'             1,005\n",
      "ll            2,222\n",
      "ask           3,198\n",
      "him           2,032\n",
      ",             1,010\n",
      "when          2,043\n",
      "he            2,002\n",
      "calls         4,455\n",
      "to            2,000\n",
      "-             1,011\n",
      "day           2,154\n",
      ".             1,012\n",
      "\"             1,000\n",
      "\"             1,000\n",
      "is            2,003\n",
      "he            2,002\n",
      "going         2,183\n",
      "to            2,000\n",
      "call          2,655\n",
      "?             1,029\n",
      "\"             1,000\n",
      "\"             1,000\n",
      "i             1,045\n",
      "have          2,031\n",
      "an            2,019\n",
      "idea          2,801\n",
      "he            2,002\n",
      "will          2,097\n",
      ",             1,010\n",
      "\"             1,000\n",
      "said          2,056\n",
      "john          2,198\n",
      ".             1,012\n",
      "\"             1,000\n",
      "i             1,045\n",
      "sent          2,741\n",
      "him           2,032\n",
      "a             1,037\n",
      "note          3,602\n",
      "just          2,074\n",
      "now           2,085\n",
      ",             1,010\n",
      "asking        4,851\n",
      "if            2,065\n",
      "he            2,002\n",
      "could         2,071\n",
      "manage        6,133\n",
      "a             1,037\n",
      "visit         3,942\n",
      ".             1,012\n",
      "\"             1,000\n",
      "it            2,009\n",
      "was           2,001\n",
      "unfortunate  15,140\n",
      ",             1,010\n",
      "in            1,999\n",
      "the           1,996\n",
      "light         2,422\n",
      "of            1,997\n",
      "subsequent    4,745\n",
      "events        2,824\n",
      ",             1,010\n",
      "that          2,008\n",
      "mr            2,720\n",
      ".             1,012\n",
      "jarvis       21,072\n",
      "should        2,323\n",
      "have          2,031\n",
      "seen          2,464\n",
      "fit           4,906\n",
      "to            2,000\n",
      "bring         3,288\n",
      "with          2,007\n",
      "him           2,032\n",
      "to            2,000\n",
      "the           1,996\n",
      "office        2,436\n",
      "that          2,008\n",
      "afternoon     5,027\n",
      "two           2,048\n",
      "of            1,997\n",
      "his           2,010\n",
      "collection    3,074\n",
      "of            1,997\n",
      "cats          8,870\n",
      ",             1,010\n",
      "and           1,998\n",
      "that          2,008\n",
      "long          2,146\n",
      "otto          8,064\n",
      ",             1,010\n",
      "who           2,040\n",
      ",             1,010\n",
      "as            2,004\n",
      "before        2,077\n",
      ",             1,010\n",
      "accompanied   5,642\n",
      "him           2,032\n",
      ",             1,010\n",
      "should        2,323\n",
      "have          2,031\n",
      "been          2,042\n",
      "fired         5,045\n",
      "by            2,011\n",
      "his           2,010\n",
      "example       2,742\n",
      "to            2,000\n",
      "the           1,996\n",
      "extent        6,698\n",
      "of            1,997\n",
      "introducing  10,449\n",
      "a             1,037\n",
      "large         2,312\n",
      "yellow        3,756\n",
      "dog           3,899\n",
      "for           2,005\n",
      "before        2,077\n",
      "the           1,996\n",
      "afternoon     5,027\n",
      "was           2,001\n",
      "ended         3,092\n",
      ",             1,010\n",
      "space         2,686\n",
      "in            1,999\n",
      "the           1,996\n",
      "office        2,436\n",
      "was           2,001\n",
      "destined     16,036\n",
      "to            2,000\n",
      "be            2,022\n",
      "at            2,012\n",
      "premium      12,882\n",
      ".             1,012\n",
      "mr            2,720\n",
      ".             1,012\n",
      "jarvis       21,072\n",
      ",             1,010\n",
      "when          2,043\n",
      "he            2,002\n",
      "had           2,018\n",
      "recovered     6,757\n",
      "from          2,013\n",
      "the           1,996\n",
      "surprise      4,474\n",
      "of            1,997\n",
      "seeing        3,773\n",
      "betty         9,306\n",
      "and           1,998\n",
      "learning      4,083\n",
      "that          2,008\n",
      "she           2,016\n",
      "had           2,018\n",
      "returned      2,513\n",
      "to            2,000\n",
      "her           2,014\n",
      "old           2,214\n",
      "situation     3,663\n",
      ",             1,010\n",
      "explained     4,541\n",
      ":             1,024\n",
      "\"             1,000\n",
      "t             1,056\n",
      "'             1,005\n",
      "ought        11,276\n",
      "i             1,045\n",
      "'             1,005\n",
      "d             1,040\n",
      "bring         3,288\n",
      "de            2,139\n",
      "kits         18,628\n",
      "along         2,247\n",
      ",             1,010\n",
      "\"             1,000\n",
      "he            2,002\n",
      "said          2,056\n",
      ".             1,012\n",
      "\"             1,000\n",
      "de            2,139\n",
      "##y           2,100\n",
      "starts        4,627\n",
      "fuss         28,554\n",
      "'             1,005\n",
      "n             1,050\n",
      "'             1,005\n",
      "wit          15,966\n",
      "'             1,005\n",
      "each          2,169\n",
      "odd           5,976\n",
      "##er          2,121\n",
      "yesterday     7,483\n",
      ",             1,010\n",
      "so            2,061\n",
      "i             1,045\n",
      "brings        7,545\n",
      "dem          17,183\n",
      "along         2,247\n",
      ".             1,012\n",
      "\"             1,000\n",
      "\n",
      "[SEP]           102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(input_ids['input_ids'])\n",
    "#print(' ,'.join(tokens))\n",
    "\n",
    "    \n",
    "    # For each token and its id...\n",
    "for token, id in zip(tokens, input_ids ['input_ids']):\n",
    "    \n",
    "    # If this is the [SEP] token, add some space around it to make it stand out.\n",
    "    if id == tokenizer.sep_token_id:\n",
    "        print('')\n",
    "    \n",
    "    # Print the token string and its ID in two columns.\n",
    "    print('{:<12} {:>6,}'.format(token, id))\n",
    "\n",
    "    if id == tokenizer.sep_token_id:\n",
    "        print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5c8e843",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7795, -6.5012, -7.9509, -8.1476, -7.4495, -8.2879, -7.9080, -7.3919,\n",
      "         -7.9965, -8.0105, -8.3358, -9.6904, -0.7795, -6.0707, -8.0976, -7.7681,\n",
      "         -5.7102, -5.0340, -6.6264, -4.2509, -4.0900, -4.0228, -6.3500, -6.1168,\n",
      "         -5.5615, -7.0696, -4.8340, -5.5944, -6.7128, -1.9254, -3.0223, -7.5082,\n",
      "         -6.9446, -4.8248, -1.6756, -2.9204, -2.7060, -4.9209, -7.1110, -6.8519,\n",
      "         -2.9864, -0.7796,  0.8783, -4.1965, -4.3146, -2.0154, -4.7170, -2.0687,\n",
      "         -6.3176, -6.9604, -3.2934, -0.8270, -2.6903,  1.4765, -1.3313, -3.9548,\n",
      "         -3.6135, -3.1975, -6.6226, -1.3334, -6.7157, -2.7310, -6.4445, -4.2075,\n",
      "          0.7457, -0.6697, -2.0554, -3.7968,  4.0790,  3.5689, -0.1246, -3.7520,\n",
      "         -0.6827, -0.8229, -4.7659, -0.0798, -0.3039, -5.2038, -1.4983,  0.6813,\n",
      "         -0.4787, -4.0973, -2.8769, -1.2445, -4.5417, -0.7143, -1.5973, -3.5011,\n",
      "         -6.4219, -4.9608, -4.5145, -2.8850, -6.1777, -4.9875, -5.6112, -2.8412,\n",
      "         -6.3343, -2.9686, -3.7946, -2.8314, -5.8041, -3.9559, -4.2235, -0.7942,\n",
      "         -6.0432, -6.5382, -6.0736, -6.4714, -6.6474, -8.3716, -6.4970, -1.8811,\n",
      "         -6.3984, -6.0926, -6.5991, -5.7027, -8.0152, -7.9549, -6.1924, -8.1274,\n",
      "         -7.0942, -6.7518, -6.1574, -7.1713, -7.2827, -5.3423, -6.0204, -7.4788,\n",
      "         -7.5618, -8.1978, -8.2249, -8.1234, -9.2723, -8.5206, -6.7304, -5.1425,\n",
      "         -6.0166, -8.2715, -8.8427, -6.4952, -8.0375, -5.9816, -8.9229, -8.1787,\n",
      "         -8.0103, -8.7609, -7.0815, -7.9717, -7.7784, -8.5027, -7.4296, -7.5747,\n",
      "         -8.2237, -7.3203, -8.8557, -7.6036, -6.7340, -5.6891, -7.1301, -7.3094,\n",
      "         -5.7016, -7.6922, -8.7373, -5.8509, -6.9860, -6.3669, -8.1429, -8.8526,\n",
      "         -8.3733, -7.9509, -8.1019, -7.2072, -6.4853, -6.8575, -7.2714, -7.8827,\n",
      "         -6.4026, -9.2542, -8.7666, -5.8949, -4.6610, -6.3961, -6.9357, -6.7264,\n",
      "         -6.8503, -7.7124, -8.5575, -7.8435, -6.9291, -5.6743, -7.5263, -6.2507,\n",
      "         -4.8135, -4.5511, -7.5704, -6.5178, -4.8837, -7.8984, -7.5957, -8.3530,\n",
      "         -6.0553, -7.0530, -6.9980, -7.4082, -6.3641, -7.0562, -5.6853, -7.8885,\n",
      "         -7.7585, -7.9203, -8.7624, -7.7930, -8.9337, -8.1756, -8.4507, -8.2830,\n",
      "         -8.9093, -8.4197, -8.6353, -9.2154, -8.4790, -6.4765, -9.0011, -7.8699,\n",
      "         -8.3030, -8.9455, -8.3786, -8.4186, -8.0240, -6.3445, -8.0170, -8.6143,\n",
      "         -8.2821, -8.6118, -8.5029, -8.3490, -8.0916, -5.4303, -7.8248, -7.0856,\n",
      "         -6.4449, -8.1011, -6.0145, -9.0209, -8.8434, -7.9596, -6.5654, -7.2741,\n",
      "         -9.2677, -8.8837, -9.1902, -8.3583, -8.7925, -9.2364, -8.0663, -8.8706,\n",
      "         -9.2361, -8.0303, -8.8632, -8.8582, -8.0292, -8.6591, -8.4451, -8.0542,\n",
      "         -8.6168, -8.5911, -7.8383, -8.4795, -6.4254, -7.6050, -7.5675, -8.1307,\n",
      "         -7.4129, -8.8584, -8.1018, -8.4862, -8.7102, -8.9525, -8.7180, -9.1848,\n",
      "         -6.7703, -8.9266, -8.6186, -8.8106, -8.8784, -8.3072, -8.7656, -8.8459,\n",
      "         -8.5473, -8.1227, -7.3398, -5.2821, -8.4093, -6.9676, -8.7964, -7.0266,\n",
      "         -7.5175, -8.2833, -7.2302, -8.1249, -7.3055, -6.4961, -7.8749, -6.1624,\n",
      "         -5.7349, -7.0750, -5.1135, -6.6756, -3.9371, -5.5891, -2.3749, -6.3891,\n",
      "         -6.2115, -6.9612, -6.7251, -8.6018, -6.6121, -8.2713, -6.3043, -5.4294,\n",
      "         -8.0423, -6.6761, -6.7574, -8.2921, -7.2786, -4.9093, -6.7468, -5.6117,\n",
      "         -7.0722, -8.6668, -8.1773, -8.1249, -8.2663, -8.4975, -7.4480, -6.3381,\n",
      "         -8.0416, -7.5586, -7.0515, -8.1597, -8.1898, -8.6865, -8.2849, -8.5260,\n",
      "         -8.5095, -8.1356, -9.0078, -8.2696, -8.9550, -7.9524, -7.0011, -6.9935,\n",
      "         -8.2785, -7.8851, -8.6368, -8.6641, -0.7795]],\n",
      "       grad_fn=<CloneBackward0>) tensor([[ 0.1663, -5.7955, -6.9042, -8.3700, -6.4841, -7.4786, -8.2754, -7.9345,\n",
      "         -7.3632, -7.3867, -6.6339, -7.6057,  0.1663, -7.7899, -7.4870, -7.1649,\n",
      "         -8.2352, -5.0704, -4.3244, -7.2332, -6.4462, -6.2509, -7.0455, -7.2674,\n",
      "         -3.7779, -4.3721, -7.3452, -6.6668, -7.5068, -6.5761, -3.6940, -6.7725,\n",
      "         -7.0780, -7.3321, -3.6794, -7.9456, -5.4709, -4.7430, -7.4365, -6.9345,\n",
      "         -0.6262,  0.1663, -4.8720, -7.0472, -7.0763, -5.3376, -7.8290, -6.4904,\n",
      "         -6.6997, -2.9521, -6.8670, -6.1845, -6.4117, -4.7281, -1.4982, -7.2019,\n",
      "         -6.9091, -2.5583, -7.1514, -5.6473, -7.3939, -0.3436, -0.7561, -6.2187,\n",
      "         -6.1672, -6.2504,  1.2621,  0.7590, -3.9648, -3.7211,  2.9112, -3.5872,\n",
      "         -4.1662, -1.3515, -5.6257, -5.1844,  1.5259,  0.7999, -4.0635, -5.6702,\n",
      "         -4.9713, -4.6429, -6.1363,  1.7184,  1.0265, -4.3148, -7.0493, -7.5376,\n",
      "         -7.6316, -6.3551, -6.6298, -6.5045, -6.6775, -6.3297, -6.9470, -1.2316,\n",
      "         -1.8186, -6.9576, -6.7472, -6.6338, -7.6721, -7.1616, -7.0245, -5.2048,\n",
      "         -4.5851, -2.7018, -4.5428, -7.3104, -2.4925, -4.0890, -8.3763, -6.3151,\n",
      "         -4.2133, -7.6324, -7.2945, -6.6975, -7.8972, -7.5672, -0.9136, -1.8366,\n",
      "         -3.6885, -7.2484, -8.4144, -7.9563, -7.9756, -8.6227, -6.4372, -7.8618,\n",
      "         -6.9485, -8.0245, -8.1063, -5.2262, -6.9356, -6.3754, -7.0722, -8.1246,\n",
      "         -6.5744, -4.9695, -5.0617, -8.0447, -8.0343, -6.3619, -8.3836, -8.7718,\n",
      "         -7.7490, -8.6238, -7.9953, -9.2881, -9.0679, -7.4129, -8.7891, -8.6114,\n",
      "         -8.0426, -7.2317, -5.5869, -4.9292, -8.1814, -7.9296, -8.1789, -7.3577,\n",
      "         -7.6082, -5.9302, -5.8993, -8.3961, -8.1169, -5.9793, -8.1958, -8.6586,\n",
      "         -4.8777, -4.5965, -6.2612, -7.2279, -8.3173, -7.9388, -7.8713, -7.8793,\n",
      "         -5.0396, -7.3703, -7.0384, -6.6323, -7.7877, -8.3004, -8.3230, -6.7301,\n",
      "         -7.8750, -5.8234, -3.9597, -6.8229, -7.6601, -5.7006, -3.9605, -6.4231,\n",
      "         -7.6651, -7.5620, -7.0101, -8.1129, -3.5503, -8.3190, -5.3345, -4.8113,\n",
      "         -7.8895, -7.8821, -7.7187, -8.2005, -7.4711, -8.2059, -3.4860, -3.6869,\n",
      "         -5.9643, -8.5104, -8.4296, -7.0597, -6.3151, -8.8260, -8.5278, -8.5931,\n",
      "         -8.4415, -8.4604, -7.3613, -6.6731, -8.1333, -8.1777, -8.2494, -6.3927,\n",
      "         -8.3002, -8.0321, -8.5335, -7.7135, -8.1944, -8.1546, -8.3775, -7.4215,\n",
      "         -8.3014, -8.3960, -7.2292, -8.3321, -7.4764, -6.2059, -7.7971, -8.3849,\n",
      "         -6.5069, -7.7583, -3.6295, -4.7266, -7.3330, -8.0654, -6.7065, -5.3610,\n",
      "         -6.3548, -8.0270, -7.0634, -8.5441, -8.0063, -7.2912, -8.4830, -7.1049,\n",
      "         -7.0316, -8.3964, -8.0737, -8.1798, -7.3488, -8.3221, -7.6015, -6.4390,\n",
      "         -8.4580, -8.2265, -7.9720, -8.0394, -8.1757, -8.1913, -8.1168, -7.3582,\n",
      "         -5.2854, -7.1275, -8.5638, -8.4109, -8.2834, -8.4524, -7.4411, -7.3893,\n",
      "         -7.1648, -8.2612, -8.4019, -7.7311, -8.3286, -8.3452, -8.1557, -8.1212,\n",
      "         -8.5891, -6.5724, -4.6356, -7.6652, -8.0059, -5.3770, -6.0211, -8.1812,\n",
      "         -7.9195, -8.3023, -7.9358, -8.1875, -8.3537, -7.2304, -7.7210, -7.6574,\n",
      "         -5.2149, -7.6835, -7.6536, -8.1614, -8.1973, -8.1370, -6.5620, -7.7000,\n",
      "         -8.1249, -6.7978, -2.5221, -5.7630, -7.3963, -6.4026, -7.4248, -7.5639,\n",
      "         -7.0625, -7.0082, -7.6717, -8.3459, -7.0877, -7.3063, -7.2763, -4.4480,\n",
      "         -3.5231, -4.7345, -6.8057, -7.5319, -6.2920, -4.9486, -7.1564, -7.4479,\n",
      "         -6.5492, -7.8456, -7.3829, -7.8542, -7.1737, -7.4863, -7.2053, -7.3067,\n",
      "         -6.6109, -7.5670, -6.0585, -6.2822, -6.1694, -7.8814, -7.5282, -7.9145,\n",
      "         -6.1672, -4.6259, -5.0019, -5.0964,  0.1662]],\n",
      "       grad_fn=<CloneBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#token input_ids to represent the input\n",
    "#token segment_ids to differentiate our segments - text and question\n",
    "output = model(torch.tensor([input_ids['input_ids']]),  token_type_ids=torch.tensor([input_ids['token_type_ids']]))\n",
    "print(output.start_logits, output.end_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d18ce8",
   "metadata": {},
   "source": [
    " The final embedding is fed to start token classifier layer. Start token classifier has single set of weights which it applies \n",
    " to every word. After taking the dot product between the output embeddings and the ‘start’ weights, model apply the softmax \n",
    " activation to produce a probability distribution over all of the words. Whichever word has the highest probability of \n",
    " being the start token is the one that model pick, for the end token model have a separate weight vector.  \n",
    "\n",
    " Model predicted the best answer by selecting the start and end tokens (start+end combination) with the largest logits.\n",
    " An answer wherein the end token falls before the start token should be excluded\n",
    " Candidate answers wherein the start or end tokens are associated with question tokens are also excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ed61d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(68) tensor(70)\n"
     ]
    }
   ],
   "source": [
    "# looking at the most probable start and end words \n",
    "answer_start = torch.argmax(output.start_logits) # the token with highest probability of being start of the answer\n",
    "answer_end = torch.argmax(output.end_logits) # the token with highest probability of being end of the answer\n",
    "\n",
    "print(answer_start, answer_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ca92660",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question:\n",
      "What did betty do as john told her about it?\n",
      "\n",
      "Answer:\n",
      "She turned white.\n"
     ]
    }
   ],
   "source": [
    "# providing answers only if the end token is after the start token \n",
    "\n",
    "if answer_end >= answer_start:\n",
    "    answer =  \" \".join(tokens[answer_start:answer_end+1])\n",
    "else:\n",
    "    print(\"Sorry! I need more information to answer this question. Can you ask another question?\")\n",
    "    \n",
    "#print(\"Text:\\n{}\".format(text.capitalize()))\n",
    "print(\"\\nQuestion:\\n{}\".format(question.capitalize()))\n",
    "print(\"\\nAnswer:\\n{}.\".format(answer.capitalize()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab3a1b0",
   "metadata": {},
   "source": [
    "BERT uses wordpiece tokenization and vocabulary size of 30,000. In BERT, rare words get broken down into subwords/pieces.\n",
    "Wordpiece tokenization uses ## to delimit tokens that have been split, for example \"Playing\" is split in to \"Play' and \"##ing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68a33bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining the broken words \n",
    "\n",
    "# Start with the first token.\n",
    "answer = tokens[answer_start]\n",
    "# Select the remaining answer tokens and join them with whitespace.\n",
    "for i in range(answer_start+1, answer_end+1):\n",
    "    # If it's a subword token, then recombine it with the previous token.\n",
    "    if tokens[i][0:2] == '##':\n",
    "        answer += tokens[i][2:]\n",
    "    # Otherwise, add a space then the token.\n",
    "    else:\n",
    "        answer += \" \" +tokens[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cec11e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the process in to a function \n",
    "\n",
    "\n",
    "def question_answer(question, text):\n",
    "    \n",
    "    #tokenize question and text in ids as a pair\n",
    "    input_ids = tokenizer.encode(question, text)\n",
    "    \n",
    "    #string version of tokenized ids\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    \n",
    "    # Search the input_ids for the first instance of the `[SEP]` token.\n",
    "    sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
    "\n",
    "    #number of tokens in segment A includes the [SEP] token istelf. - question\n",
    "    num_seg_a = sep_idx+1\n",
    "\n",
    "    #number of tokens in segment B - text\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "    \n",
    "    # constructing the list of 0s and 1s\n",
    "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "    \n",
    "    # There should be a segment_id for every input token.\n",
    "    assert len(segment_ids) == len(input_ids)\n",
    "    \n",
    "    #model output using input_ids and segment_ids\n",
    "    output = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))\n",
    "    \n",
    "    #reconstructing the answer\n",
    "    answer_start = torch.argmax(output.start_logits)\n",
    "    answer_end = torch.argmax(output.end_logits)\n",
    "\n",
    "    if answer_end >= answer_start:\n",
    "        answer = tokens[answer_start]\n",
    "        for i in range(answer_start+1, answer_end+1):\n",
    "            if tokens[i][0:2] == \"##\":\n",
    "                answer += tokens[i][2:]\n",
    "            else:\n",
    "                answer += \" \" + tokens[i]\n",
    "                \n",
    "    if answer.startswith(\"[CLS]\"):\n",
    "        answer = \"Sorry! I need more information to answer this question. Can you ask another question?.\"\n",
    "    print(\"\\nAnswer:\\n{}\".format(answer.capitalize()))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1904366",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      "5 percent\n"
     ]
    }
   ],
   "source": [
    "text = PDF_text\n",
    "question = ' on 2/19 the yield increased by?'\n",
    "question_answer(question,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59f1081",
   "metadata": {},
   "source": [
    "# Merging the model and the PDF retrived data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b79d183f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! i am Max. How i can help you\n",
      " on 2/19 the yield increased by what percentage ?\n",
      "\n",
      "Answer:\n",
      "5\n",
      "\n",
      "Do you want to ask another question based on this text (Y/N)? Y\n",
      "\n",
      "Please enter your question: \n",
      "on 2/19 the yield increased by?\n",
      "\n",
      "Answer:\n",
      "5 percent\n",
      "\n",
      "Do you want to ask another question based on this text (Y/N)? Y\n",
      "\n",
      "Please enter your question: \n",
      "who is chief investment officer at Beaufort Investment?\n",
      "\n",
      "Answer:\n",
      "Balkham\n",
      "\n",
      "Do you want to ask another question based on this text (Y/N)? N\n",
      "\n",
      "Bye!\n"
     ]
    }
   ],
   "source": [
    "print('Hello! i am Max. How i can help you')\n",
    "text = PDF_text\n",
    "question = input()\n",
    "\n",
    "while True:\n",
    "    question_answer(question, text)\n",
    "    \n",
    "    flag = True\n",
    "    flag_N = False\n",
    "    \n",
    "    while flag:\n",
    "        response = input(\"\\nDo you want to ask another question based on this text (Y/N)? \")\n",
    "        if response[0] == \"Y\":\n",
    "            question = input(\"\\nPlease enter your question: \\n\")\n",
    "            flag = False\n",
    "        elif response[0] == \"N\":\n",
    "            print(\"\\nBye!\")\n",
    "            flag = False\n",
    "            flag_N = True\n",
    "            \n",
    "    if flag_N == True:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe220ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d802e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f40787",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
